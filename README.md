# 🌟 HeartSense 

Bienvenue dans **HeartSense**, une application moderne, puissante et 100 % open source conçue pour répondre à vos besoins en toute simplicité. Créée avec soin, cette solution est **faite maison**, entièrement **auto-hébergée**, et dédiée aux passionnés de liberté numérique et de transparence.

---

## 🚀 Fonctionnalités Principales

### 🌐 **Application auto-hébergée**
- Gardez un contrôle total sur vos données.
- Déployez facilement votre instance sur votre serveur.
- Aucun besoin de dépendances externes : tout est optimisé pour une utilisation privée.

### 🛠️ **Entièrement open source**
- Code source disponible sur [GitHub](#).
- Contributions bienvenues pour améliorer et enrichir le projet.
- Auditable pour garantir une transparence maximale.

### ✨ **Fait maison, pour tous**
- Conçu pour les petites équipes, les développeurs et les passionnés d'open source.
- Interface intuitive et fonctionnalités avancées, développées avec amour.

### 🔒 **Sécurisé et évolutif**
- Gestion des utilisateurs et permissions personnalisables.
- Optimisé pour une performance fluide sur des serveurs légers.

---

## 🎯 Objectifs du Projet

MonProjet vise à offrir une solution clé en main, simple à déployer et facile à adapter selon vos besoins. 
L’accent est mis sur :
- **Transparence** : Pas de surprise cachée. Vous contrôlez tout.
- **Liberté numérique** : Hébergez vos propres outils, sans dépendance à des services tiers.
- **Partage et communauté** : Une plateforme qui évolue grâce à vous.

---
## 🐳 Utilisation avec Docker


### Étapes d’installation :

1. Clonez le dépôt :
   ```bash
   git clone https://github.com/gabriel25115CG/HeartSenseAI.git

2. Lancer le frontend et l'API avec Docker Compose
   ```bash 
   docker-compose up --build

🤖 Partie IA (Ollama)

Si vous souhaitez exécuter la partie IA avec Ollama, suivez ces étapes :

1. Téléchargez et installez Ollama sur votre machine.
2. Une fois Ollama installé, lancez le modèle Llama 3.2 avec la commande suivante :
   
   ```bash 
   ollama run llama3.2


